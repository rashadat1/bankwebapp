{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the autoformer model to check format our data should be in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import AutoformerForPrediction\n",
    "import os\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "file = hf_hub_download(repo_id=\"hf-internal-testing/tourism-monthly-batch\",filename=\"train-batch.pt\", repo_type=\"dataset\")\n",
    "# batch has type dict\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = AutoformerForPrediction.from_pretrained(\"huggingface/autoformer-tourism-monthly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"past_values shape: {batch['past_values'].shape}\")\n",
    "print(f\"past_time_features shape: {batch['past_time_features'].shape}\")\n",
    "print(f\"future_values shape: {batch['future_values'].shape}\")\n",
    "print(f\"future_time_features shape: {batch['future_time_features'].shape}\")\n",
    "print(f\"past_observed_mask shape: {batch['past_observed_mask'].shape}\")\n",
    "print(f\"static_categorical_features shape: {batch['static_categorical_features'].shape}\")\n",
    "# we see the data is all torch tensors as we would expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If mps is available to speed up our calculations - move all of the data for inference / training and the model to mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available else 'cpu')\n",
    "\n",
    "past_values = batch['past_values'].to(device)\n",
    "past_time_features = batch['past_time_features'].to(device)\n",
    "future_values = batch['future_values'].to(device)\n",
    "future_time_features = batch['future_time_features'].to(device)\n",
    "past_observed_mask = batch['past_observed_mask'].to(device)\n",
    "static_categorical_features = batch['static_categorical_features'].to(device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_cpu_fallback(model, device, **inputs):\n",
    "    # Move model to CPU\n",
    "    model_cpu = model.to('cpu')\n",
    "    # Move inputs to CPU\n",
    "    inputs_on_cpu = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "    # Perform forward pass on CPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model_cpu(**inputs_on_cpu)\n",
    "    # Move outputs back to the original device\n",
    "    outputs_on_device = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in outputs.items()}\n",
    "    return outputs_on_device\n",
    "\n",
    "def generate_with_cpu_fallback(model, device, **inputs):\n",
    "    # Move model to CPU\n",
    "    model_cpu = model.to('cpu')\n",
    "    # Move inputs to CPU\n",
    "    inputs_on_cpu = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "    # Perform generate pass on CPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model_cpu.generate(**inputs_on_cpu)\n",
    "    # Move outputs back to the original device\n",
    "    if isinstance(outputs, tuple):\n",
    "        outputs_on_device = tuple([o.to(device) for o in outputs])\n",
    "    elif isinstance(outputs, torch.Tensor):\n",
    "        outputs_on_device = outputs.to(device)\n",
    "    else:\n",
    "        outputs_on_device = outputs\n",
    "    return outputs_on_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference to generate last hidden states output\n",
    "outputs = forward_with_cpu_fallback(\n",
    "    model,\n",
    "    device,\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    static_categorical_features=static_categorical_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference to generate time series output\n",
    "predictions = generate_with_cpu_fallback(\n",
    "    model,\n",
    "    device,\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    static_categorical_features=static_categorical_features,\n",
    "    future_time_features=future_time_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the generated predictions are 100 sequences for each of the 64 output sequences. Each sequence has length 24\n",
    "# we average along the 2nd dimension (get the mean of the 100 sequences for each time step in the output) leaving us \n",
    "# with shape [64,24]\n",
    "print(predictions.sequences.shape)\n",
    "print(predictions.sequences.mean(dim=1))\n",
    "print(predictions.sequences.mean(dim=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, one provides both past and future values as well as possible additional features\n",
    "\\\n",
    "\\\n",
    "In particular let's supply past_values, past_time_features, past_observed_mask, static_categorical_features, future_values, and future_time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trans_df = pd.read_csv('/Users/tarikrashada/Downloads/Transactions - Sheet1.csv')\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with sequence lengths. But the underlying question is, given transaction data covering the previous n months with a frequency of a few transactions per day can we predict the transactions that will occur in the next k days. In particular we want to know the approximate aggregate that will be spent.\n",
    "\\\n",
    "\\\n",
    "It is possible that this is easier to predict but will require some model alterations. Let's start with what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. how this will work\n",
    "'''\n",
    "obj = [1,2,3,4,5,6,7,8,9,10]\n",
    "past_length = 3\n",
    "future_length = 4\n",
    "[1,2,3] -> [4,5,6,7]\n",
    "[2,3,4] -> [5,6,7,8]\n",
    "[3,4,5] -> [6,7,8,9]\n",
    "[4,5,6] -> [7,8,9,10]\n",
    "\n",
    "len of dataset = 4 = len(obj) - past_length - future_length + 1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [1,2,3,4,5,6,7,8,9,10]\n",
    "past_start = 0\n",
    "past_length = 3\n",
    "future_length = 4\n",
    "past_end = past_start + past_length\n",
    "future_end = past_end + future_length\n",
    "\n",
    "print(v[past_start:past_end])\n",
    "print(v[past_end:future_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse dataframe\n",
    "\n",
    "trans_df.sort_values(by='Transaction Date',inplace=True)\n",
    "trans_df.reset_index(inplace=True,drop=True)\n",
    "trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df.dropna(subset=['Debit'])\n",
    "trans_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['Debit'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.iloc[0:10]['Debit'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['Transaction Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['Transaction Date'] = pd.to_datetime(trans_df['Transaction Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "days_in_months = np.array([0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "\n",
    "days_in_months[trans_df['Transaction Date'].dt.month]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sin and cos functions to generate day of the month cyclical time features. These help the model to understand month to month periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "days_in_months = np.array([0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "\n",
    "def generate_day_of_month_features(dates):\n",
    "    \n",
    "    day_cos = np.cos(2 * np.pi * dates.dt.day / days_in_months[dates.dt.month])\n",
    "    day_sin = np.sin(2 * np.pi * dates.dt.day / days_in_months[dates.dt.month])\n",
    "    \n",
    "    date_strings = dates.dt.date.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    return np.vstack([day_cos, day_sin]).T, np.vstack([date_strings])\n",
    "\n",
    "def generate_age_features(length):\n",
    "    \n",
    "    age_features = np.arange(length) / length\n",
    "    return age_features.reshape(-1,1)\n",
    "\n",
    "def generate_time_features(dates):\n",
    "    \n",
    "    day_features, date_data = generate_day_of_month_features(dates)\n",
    "    age_features = generate_age_features(len(dates))\n",
    "    #return np.hstack([day_features, age_features])\n",
    "    return day_features, date_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating day of month and age features, we concatenate the features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_month_features = generate_day_of_month_features(trans_df['Transaction Date'])\n",
    "print(day_of_month_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_time_features(trans_df['Transaction Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self,df,past_length,future_length):\n",
    "        self.df = df\n",
    "        self.past_length = past_length\n",
    "        self.future_length = future_length\n",
    "    \n",
    "    # the standard len() works by calling an object's __len__ method\n",
    "    # here we define our __len__ method to be the number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.df) - (self.past_length + self.future_length) + 1\n",
    "    \n",
    "    # defines behavior for when an item is accessed self[key]\n",
    "    def __getitem__(self,idx):\n",
    "        past_start = idx\n",
    "        past_end = idx + self.past_length\n",
    "        future_end = past_end + self.future_length\n",
    "        \n",
    "        past_seq = self.df.iloc[past_start:past_end]\n",
    "        fut_seq = self.df.iloc[past_end:future_end]\n",
    "        \n",
    "        past_values = past_seq['Debit'].values\n",
    "        future_values = fut_seq['Debit'].values\n",
    "        \n",
    "        past_observed_mask = ~np.isnan(past_values)\n",
    "        \n",
    "        static_categorical_features = np.ones((1,))\n",
    "        \n",
    "        past_time_features, dates_past = generate_time_features(past_seq['Transaction Date'])\n",
    "        future_time_features, dates_future = generate_time_features(fut_seq['Transaction Date'])\n",
    "        \n",
    "        return {\n",
    "            'past_values': torch.tensor(past_values, dtype=torch.float32, requires_grad=True),\n",
    "            'past_time_features': torch.tensor(past_time_features, dtype=torch.float32, requires_grad=True),\n",
    "            'past_observed_mask': torch.tensor(past_observed_mask, dtype=torch.bool),\n",
    "            'static_categorical_features': torch.tensor(static_categorical_features, dtype=torch.long),\n",
    "            'future_values': torch.tensor(future_values, dtype=torch.float32, requires_grad=True),\n",
    "            'future_time_features': torch.tensor(future_time_features, dtype=torch.float32, requires_grad=True),\n",
    "            'dates_past': dates_past,\n",
    "            'dates_future': dates_future\n",
    "        }\n",
    "\n",
    "past_length = 61\n",
    "future_length = 24 \n",
    "\n",
    "dataset = TimeSeriesDataset(trans_df,past_length,future_length)\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Separate out the 'dates_past' and 'dates_future' which are lists of np.datetime64\n",
    "    dates_past = [item['dates_past'] for item in batch]\n",
    "    dates_future = [item['dates_future'] for item in batch]\n",
    "    \n",
    "    dates_past = np.array(dates_past).reshape(len(batch), -1)\n",
    "    dates_future = np.array(dates_future).reshape(len(batch), -1)\n",
    "    # Handle the rest of the data normally (convert to tensors)\n",
    "    batch_no_dates = [{k: v for k, v in item.items() if k not in ['dates_past', 'dates_future']} for item in batch]\n",
    "    \n",
    "    # Use the default collate function for the rest\n",
    "    collated_batch = torch.utils.data.default_collate(batch_no_dates)\n",
    "    \n",
    "    # Add back the dates\n",
    "    collated_batch['dates_past'] = dates_past\n",
    "    collated_batch['dates_future'] = dates_future\n",
    "    \n",
    "    \n",
    "    return collated_batch\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"past_values shape: {batch['past_values'].shape}\")\n",
    "    print(f\"future_values shape: {batch['future_values'].shape}\")\n",
    "    print(f\"past_time_features shape: {batch['past_time_features'].shape}\")\n",
    "    print(f\"future_time_features shape: {batch['future_time_features'].shape}\")\n",
    "    print(f\"static_categorical_features shape: {batch['static_categorical_features'].shape}\")\n",
    "    print(f\"past_observed_mask shape: {batch['past_observed_mask'].shape}\")\n",
    "    print(f\"dates_past shape: {batch['dates_past'].shape}\")\n",
    "    print(f\"dates_future shape: {batch['dates_future'].shape}\")\n",
    "    break\n",
    "\n",
    "num_time_features = batch['past_time_features'].shape[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['dates_future'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially tried get_scheduler and copied arguments from hugging face's fine-tune a model article.\\\n",
    "Other things we can try - changing the optimizer, adjusting batch_size or other parts of config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import get_scheduler, AutoformerForPrediction\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model_ckpt = \"huggingface/autoformer-tourism-monthly\"\n",
    "model = AutoformerForPrediction.from_pretrained(model_ckpt)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer = optimizer, mode = 'min', factor = 0.1, patience = 2, verbose = True)\n",
    "\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_batch = { k : v for k, v in batch.items()}\n",
    "            outputs = model(\n",
    "                past_values=input_batch['past_values'],\n",
    "                past_time_features=input_batch['past_time_features'],\n",
    "                past_observed_mask=input_batch['past_observed_mask'],\n",
    "                static_categorical_features=input_batch['static_categorical_features'],\n",
    "                future_values=input_batch['future_values'],\n",
    "                future_time_features=input_batch['future_time_features'])\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(test_loader)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_batch = { k : v for k, v in batch.items()}\n",
    "        outputs = model(\n",
    "            past_values=input_batch['past_values'],\n",
    "            past_time_features=input_batch['past_time_features'],\n",
    "            past_observed_mask=input_batch['past_observed_mask'],\n",
    "            static_categorical_features=input_batch['static_categorical_features'],\n",
    "            future_values=input_batch['future_values'],\n",
    "            future_time_features=input_batch['future_time_features'])\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        if (step + 1) % 1 == 0:\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Step[{step + 1}/{len(train_loader)}], Loss: {running_loss}\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    val_avg_loss = evaluate(model,test_loader)\n",
    "    lr_scheduler.step(val_avg_loss)\n",
    "    tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Validation Loss: {val_avg_loss}\")\n",
    "    \n",
    "progress_bar.close()\n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_vals = []\n",
    "future_vals = []\n",
    "predictions_mean_all = []\n",
    "predictions_min_all = []\n",
    "predictions_max_all = []\n",
    "predictions_median_all = []\n",
    "predictions_65th_all = []\n",
    "predictions_75th_all = []\n",
    "predictions_85th_all = []\n",
    "past_dates = []\n",
    "future_dates = []\n",
    "for batch in train_loader:\n",
    "    \n",
    "    sums_pred = []\n",
    "    sums_target = []\n",
    "    \n",
    "    input_batch = { k : v for k, v in batch.items()}\n",
    "    outputs = model.generate(\n",
    "        past_values=input_batch['past_values'],\n",
    "        past_time_features=input_batch['past_time_features'],\n",
    "        past_observed_mask=input_batch['past_observed_mask'],\n",
    "        static_categorical_features=input_batch['static_categorical_features'],\n",
    "        future_time_features=input_batch['future_time_features'],\n",
    "    )\n",
    "    \n",
    "    past_vals.append(input_batch['past_values'])\n",
    "    future_vals.append(input_batch['future_values'])\n",
    "    past_dates.append(input_batch['dates_past'])\n",
    "    future_dates.append(input_batch['dates_future'])\n",
    "    \n",
    "    predictions_85th = torch.quantile(outputs.sequences, 0.85, dim=1)\n",
    "    predictions_75th = torch.quantile(outputs.sequences, 0.75, dim=1)\n",
    "    predictions_65th = torch.quantile(outputs.sequences, 0.65, dim=1)\n",
    "    predictions_min = outputs.sequences.min(dim=1)[0]\n",
    "    predictions_mean = outputs.sequences.mean(dim=1)\n",
    "    predictions_max = outputs.sequences.max(dim=1)[0]\n",
    "    predictions_median = outputs.sequences.median(dim=1)[0]\n",
    "    \n",
    "    predictions_65th_all.append(predictions_65th)\n",
    "    predictions_75th_all.append(predictions_75th)\n",
    "    predictions_85th_all.append(predictions_85th)\n",
    "    predictions_min_all.append(predictions_min)\n",
    "    predictions_mean_all.append(predictions_mean)\n",
    "    predictions_max_all.append(predictions_max)\n",
    "    predictions_median_all.append(predictions_median)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_residuals_min = []\n",
    "batch_residuals_mean = []\n",
    "batch_residuals_max = []\n",
    "batch_residuals_median = []\n",
    "for i in range(len(predictions_mean_all)):\n",
    "    batch_target = future_vals[i]\n",
    "    sum_target = batch_target.sum(dim=1)\n",
    "    \n",
    "    batch_prediction_min = predictions_min_all[i]\n",
    "    batch_prediction_mean = predictions_mean_all[i]\n",
    "    batch_prediction_max = predictions_max_all[i]\n",
    "    batch_prediction_median = predictions_median_all[i]\n",
    "    \n",
    "    sum_pred_min = batch_prediction_min.sum(dim=1)\n",
    "    sum_pred_mean = batch_prediction_mean.sum(dim=1)\n",
    "    sum_pred_max = batch_prediction_max.sum(dim=1)\n",
    "    sum_pred_median = batch_prediction_median.sum(dim=1)\n",
    "    \n",
    "    residuals_min = (sum_pred_min - sum_target).detach()\n",
    "    residuals_mean = (sum_pred_mean - sum_target).detach()\n",
    "    residuals_max = (sum_pred_max - sum_target).detach()\n",
    "    residuals_median = (sum_pred_median - sum_target).detach()\n",
    "    \n",
    "    batch_residuals_min.append(residuals_min)\n",
    "    batch_residuals_mean.append(residuals_mean)\n",
    "    batch_residuals_max.append(residuals_max)\n",
    "    batch_residuals_median.append(residuals_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 batches in train_dataloader. Each batch has size 64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The future vals has elements that are the input_batch['future_values'] for each batch, that is the targets for each of the train_loader batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms depict the residual per predicted sequence in each batch from the train_dataloader. So if there are 64 batches it will sum up all of the transanction values and take the difference between this value and the sum of all of the future values in the batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for residual in batch_residuals_mean:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(residual, bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title('Histogram of Residuals')\n",
    "    plt.xlabel('Residual')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to take an input sequence and get the corresponding future sequence for it. Then plot these for any pair of input sequence, future value sequence - for one sequence in one batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 batches. Each batch has size 64. The past lengths are 61 and the future lengths are 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prediction_plot(sequence_index, batch_index):\n",
    "    past_vals_plot = past_vals[batch_index][sequence_index].detach().numpy()\n",
    "    past_dates_plot = past_dates[batch_index][sequence_index]\n",
    "\n",
    "    future_vals_plot = future_vals[batch_index][sequence_index].detach().numpy()\n",
    "    future_dates_plot = future_dates[batch_index][sequence_index]\n",
    "\n",
    "    predictions_mean_plot = predictions_mean_all[batch_index][sequence_index].numpy()\n",
    "    predictions_max_plot = predictions_max_all[batch_index][sequence_index].numpy()\n",
    "    predictions_median_plot = predictions_median_all[batch_index][sequence_index].numpy()\n",
    "    predictions_65_plot = predictions_65th_all[batch_index][sequence_index].numpy()\n",
    "    predictions_75_plot = predictions_75th_all[batch_index][sequence_index].numpy()\n",
    "    predictions_85_plot = predictions_85th_all[batch_index][sequence_index].numpy()\n",
    "    \n",
    "    all_values_mean = np.concatenate([past_vals_plot, predictions_mean_plot])\n",
    "    all_values_max = np.concatenate([past_vals_plot, predictions_max_plot])\n",
    "    all_values_median = np.concatenate([past_vals_plot, predictions_median_plot])\n",
    "    all_dates = np.concatenate([past_dates_plot, future_dates_plot])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the actual past transactions\n",
    "    plt.plot(past_dates_plot, np.cumsum(past_vals_plot), label=\"Actual Past Transactions\", color='blue')\n",
    "\n",
    "    # Plot the predicted future transactions (Mean)\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_mean_plot), label=\"Predicted Future Transactions (Mean)\", color='orange', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(future_vals_plot), label=\"Predicted Future Transactions (Actual)\", color='blue', linestyle='--')\n",
    "\n",
    "    #plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_65_plot), label=\"Predicted Future Transactions (65th Percentile)\", color='green', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_75_plot), label=\"Predicted Future Transactions (75th Percentile)\", color='purple', linestyle='--')\n",
    "    \n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_85_plot), label=\"Predicted Future Transactions (85th Percentile)\", color='black', linestyle='--')\n",
    "\n",
    "    # Plot the predicted future transactions (Max)\n",
    "    #plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_max_plot), label=\"Predicted Future Transactions (Max)\", color='red', linestyle='--')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Transaction Amount')\n",
    "    plt.title('Actual and Predicted Transactions (Mean and Max)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    result_dict = {\"Mean\" : np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_mean_plot)[-1], \"75th\" : np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_75_plot)[-1], \"85th\" : np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_85_plot)[-1]}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_expense_predictions = prediction_plot(sequence_index=0, batch_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the total amount we expect a customer to spend over the whole time period (starting from past_values through to the end of the prediction window) and subtract this from the income over this period or the balance at the beginning of the period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity let's say this amount is 3k NGN then we can make a dictionary for amount left over for each prediction scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_over_period = 3000\n",
    "curr_bal = 700\n",
    "thresh = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_potential = {key : income_over_period - value for (key,value) in transact_expense_predictions.items()}\n",
    "savings_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdraw_amount = min(savings_potential['75th'], curr_bal * thresh)\n",
    "withdraw_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can change the configuration and make this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_features_(dates):\n",
    "    \n",
    "    day_features = generate_day_of_month_features(dates)\n",
    "    age_features = generate_age_features(len(dates))\n",
    "    return np.hstack([day_features, age_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "\n",
    "past_length = 100\n",
    "future_length = 80\n",
    "\n",
    "dataset = TimeSeriesDataset(trans_df,past_length,future_length)\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"past_values shape: {batch['past_values'].shape}\")\n",
    "    print(f\"future_values shape: {batch['future_values'].shape}\")\n",
    "    print(f\"past_time_features shape: {batch['past_time_features'].shape}\")\n",
    "    print(f\"future_time_features shape: {batch['future_time_features'].shape}\")\n",
    "    print(f\"static_categorical_features shape: {batch['static_categorical_features'].shape}\")\n",
    "    print(f\"past_observed_mask shape: {batch['past_observed_mask'].shape}\")\n",
    "    print(f\"dates_past shape: {batch['dates_past'].shape}\")\n",
    "    print(f\"dates_future shape: {batch['dates_future'].shape}\")\n",
    "    break\n",
    "\n",
    "num_time_features = batch['past_time_features'].shape[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconfigure for longer context and prediction windows\n",
    "from transformers import get_scheduler, AutoformerForPrediction, AutoformerConfig\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "config2 = AutoformerConfig.from_pretrained('huggingface/autoformer-tourism-monthly')\n",
    "# future values has length 80\n",
    "# past values has length 100\n",
    "\n",
    "# sequence length of past values must be larger than the context_length of the model\n",
    "# and the past sequence length = context_length + max(lags_sequence)\n",
    "config2.context_length = 63\n",
    "config2.prediction_length = 80\n",
    "\n",
    "model2 = AutoformerForPrediction.from_pretrained('huggingface/autoformer-tourism-monthly',\n",
    "                                                config=config2,\n",
    "                                                ignore_mismatched_sizes=True)\n",
    "\n",
    "# num_features (length of time_features) = num_time_features + num_dynamic_real_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import get_scheduler, AutoformerForPrediction\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4, weight_decay = 1e-5)\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer = optimizer, mode = 'min', factor = 0.1, patience = 2, verbose = True)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_batch = { k : v for k, v in batch.items()}\n",
    "            outputs = model(\n",
    "                past_values=input_batch['past_values'],\n",
    "                past_time_features=input_batch['past_time_features'],\n",
    "                past_observed_mask=input_batch['past_observed_mask'],\n",
    "                static_categorical_features=input_batch['static_categorical_features'],\n",
    "                future_values=input_batch['future_values'],\n",
    "                future_time_features=input_batch['future_time_features'])\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(test_loader)\n",
    "\n",
    "model2.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_batch = { k : v for k, v in batch.items() }\n",
    "        outputs = model2(\n",
    "            past_values=input_batch['past_values'],\n",
    "            past_time_features=input_batch['past_time_features'],\n",
    "            past_observed_mask=input_batch['past_observed_mask'],\n",
    "            static_categorical_features=input_batch['static_categorical_features'],\n",
    "            future_values=input_batch['future_values'],\n",
    "            future_time_features=input_batch['future_time_features'])\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        if (step + 1) % 10 == 0:\n",
    "            avg_loss = running_loss / 10\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Step[{step + 1}/{len(train_loader)}], Loss: {avg_loss}\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    val_avg_loss = evaluate(model2,test_loader)\n",
    "    lr_scheduler.step(val_avg_loss)\n",
    "    \n",
    "    epoch_avg_loss = epoch_loss / len(train_loader)\n",
    "    tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Training Loss: {epoch_avg_loss}, Validation Loss: {val_avg_loss}\")\n",
    "    \n",
    "progress_bar.close()\n",
    "    \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_vals = []\n",
    "future_vals = []\n",
    "predictions_mean_all = []\n",
    "predictions_min_all = []\n",
    "predictions_max_all = []\n",
    "predictions_median_all = []\n",
    "predictions_65th_all = []\n",
    "predictions_75th_all = []\n",
    "predictions_85th_all = []\n",
    "past_dates = []\n",
    "future_dates = []\n",
    "for batch in train_loader:\n",
    "    \n",
    "    sums_pred = []\n",
    "    sums_target = []\n",
    "    \n",
    "    input_batch = { k : v for k, v in batch.items()}\n",
    "    outputs = model2.generate(\n",
    "        past_values=input_batch['past_values'],\n",
    "        past_time_features=input_batch['past_time_features'],\n",
    "        past_observed_mask=input_batch['past_observed_mask'],\n",
    "        static_categorical_features=input_batch['static_categorical_features'],\n",
    "        future_time_features=input_batch['future_time_features'],\n",
    "    )\n",
    "    \n",
    "    past_vals.append(input_batch['past_values'])\n",
    "    future_vals.append(input_batch['future_values'])\n",
    "    past_dates.append(input_batch['dates_past'])\n",
    "    future_dates.append(input_batch['dates_future'])\n",
    "    \n",
    "    predictions_85th = torch.quantile(outputs.sequences, 0.85, dim=1)\n",
    "    predictions_75th = torch.quantile(outputs.sequences, 0.75, dim=1)\n",
    "    predictions_65th = torch.quantile(outputs.sequences, 0.65, dim=1)\n",
    "    predictions_min = outputs.sequences.min(dim=1)[0]\n",
    "    predictions_mean = outputs.sequences.mean(dim=1)\n",
    "    predictions_max = outputs.sequences.max(dim=1)[0]\n",
    "    predictions_median = outputs.sequences.median(dim=1)[0]\n",
    "    \n",
    "    predictions_65th_all.append(predictions_65th)\n",
    "    predictions_75th_all.append(predictions_75th)\n",
    "    predictions_85th_all.append(predictions_85th)\n",
    "    predictions_min_all.append(predictions_min)\n",
    "    predictions_mean_all.append(predictions_mean)\n",
    "    predictions_max_all.append(predictions_max)\n",
    "    predictions_median_all.append(predictions_median)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(past_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_dates[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prediction_plot(sequence_index, batch_index):\n",
    "    past_vals_plot = past_vals[batch_index][sequence_index].detach().numpy()\n",
    "    past_dates_plot = past_dates[batch_index][sequence_index]\n",
    "\n",
    "    future_vals_plot = future_vals[batch_index][sequence_index].detach().numpy()\n",
    "    future_dates_plot = future_dates[batch_index][sequence_index]\n",
    "\n",
    "    predictions_mean_plot = predictions_mean_all[batch_index][sequence_index].numpy()\n",
    "    predictions_max_plot = predictions_max_all[batch_index][sequence_index].numpy()\n",
    "    predictions_median_plot = predictions_median_all[batch_index][sequence_index].numpy()\n",
    "    predictions_65_plot = predictions_65th_all[batch_index][sequence_index].numpy()\n",
    "    predictions_75_plot = predictions_75th_all[batch_index][sequence_index].numpy()\n",
    "    predictions_85_plot = predictions_85th_all[batch_index][sequence_index].numpy()\n",
    "    \n",
    "    all_values_mean = np.concatenate([past_vals_plot, predictions_mean_plot])\n",
    "    all_values_max = np.concatenate([past_vals_plot, predictions_max_plot])\n",
    "    all_values_median = np.concatenate([past_vals_plot, predictions_median_plot])\n",
    "    all_dates = np.concatenate([past_dates_plot, future_dates_plot])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the actual past transactions\n",
    "    plt.plot(past_dates_plot, np.cumsum(past_vals_plot), label=\"Actual Past Transactions\", color='blue')\n",
    "\n",
    "    # Plot the predicted future transactions (Mean)\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_mean_plot), label=\"Predicted Future Transactions (Mean)\", color='orange', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(future_vals_plot), label=\"Predicted Future Transactions (Actual)\", color='blue', linestyle='--')\n",
    "\n",
    "    #plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_65_plot), label=\"Predicted Future Transactions (65th Percentile)\", color='green', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_75_plot), label=\"Predicted Future Transactions (75th Percentile)\", color='purple', linestyle='--')\n",
    "    \n",
    "    plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_85_plot), label=\"Predicted Future Transactions (85th Percentile)\", color='black', linestyle='--')\n",
    "\n",
    "    # Plot the predicted future transactions (Max)\n",
    "    #plt.plot(future_dates_plot, np.cumsum(past_vals_plot)[-1] + np.cumsum(predictions_max_plot), label=\"Predicted Future Transactions (Max)\", color='red', linestyle='--')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Transaction Amount')\n",
    "    plt.title('Actual and Predicted Transactions Past and Future Window')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(future_dates_plot, np.cumsum(predictions_mean_plot), label=\"Predicted Future Transactions (Mean)\", color='orange', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(future_vals_plot), label=\"Predicted Future Transactions (Actual)\", color='blue', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(predictions_65_plot), label=\"Predicted Future Transactions (65th Percentile)\", color='green', linestyle='--')\n",
    "\n",
    "    plt.plot(future_dates_plot, np.cumsum(predictions_75_plot), label=\"Predicted Future Transactions (75th Percentile)\", color='purple', linestyle='--')\n",
    "    \n",
    "    plt.plot(future_dates_plot, np.cumsum(predictions_85_plot), label=\"Predicted Future Transactions (85th Percentile)\", color='black', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Predicted Transaction Amount')\n",
    "    plt.title('Actual and Predicted Transactions Future Window')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    result_dict = {\"Mean\" : np.cumsum(predictions_mean_plot)[-1], \"65th\" : np.cumsum(predictions_65_plot)[-1], \"75th\" : np.cumsum(predictions_75_plot)[-1], \"85th\" : np.cumsum(predictions_85_plot)[-1]}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cum_sums = prediction_plot(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cum_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_potential = {key : 3100 - value for key,value in prediction_cum_sums.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's conclude that depending on how aggressive this customer wants to be with their saving - they can save between $1000 and $600 in this month. We will adjust these values down by some buffer. Each week we will take the transaction data, cumulatively sum it up and adjust down or up based on the current trend in their spending and how it compares to what our model is predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will format the savings tab, move this into some Python file to create a Flask app containing the model so that we can make an API call to the endpoint that serves the model and send the predictions as a response to the frontend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
